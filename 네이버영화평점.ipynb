{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "네이버영화평점.ipynb",
      "private_outputs": true,
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOu1MXII0Xcv6G4rDPpBN+W",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HayunJin/open_api/blob/main/%EB%84%A4%EC%9D%B4%EB%B2%84%EC%98%81%ED%99%94%ED%8F%89%EC%A0%90.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3zgvpSphknFP"
      },
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "from bs4 import BeautifulSoup\n",
        "import urllib.request\n",
        "from urllib.parse import quote\n",
        "import json\n",
        "import re\n",
        "import requests\n",
        "import pandas as pd\n",
        "\n",
        "df = pd.DataFrame(columns = [ 'navertitle', 'naversubtitle', 'naveruserScore', 'spScore'])\n",
        "mv = df\n",
        "#네이버 검색 Open API 사용 요청시 얻게되는 정보를 입력합니다\n",
        "naver_client_id = \"naver_client_id\"\n",
        "naver_client_secret = \"naver_client_secret\"\n",
        " \n",
        "def cleanhtml(raw_html):\n",
        "  cleanr = re.compile('<.*?>')\n",
        "  cleantext = re.sub(cleanr, '', raw_html)\n",
        "  return cleantext\n",
        "\n",
        "\n",
        "#     title = movie\n",
        "#     director = name + '|'\n",
        "#     encText = urllib.parse.quote(title)\n",
        "#     display = '&display=100'\n",
        "#     yearfrom = '&yearfrom=2010'\n",
        "#     yearto = '&yearto=2015'\n",
        "#     url = \"https://openapi.naver.com/v1/search/movie?query=\" + encText + display + yearfrom + yearto # json 결과\n",
        "#     # url = \"https://openapi.naver.com/v1/search/blog.xml?query=\" + encText # xml 결과\n",
        "\n",
        "#     url = \"https://openapi.naver.com/v1/search/movie?query=\" + encText + display + yearfrom + yearto # json 결과\n",
        "\n",
        "def searchByTitle(title, yearfrom, yearto):\n",
        "    encText = urllib.parse.quote(title)\n",
        "    display = '&display=30'\n",
        "    yearfrom = '&yearfrom='+yearfrom\n",
        "    yearto = '&yearto='+yearto\n",
        "    myurl = \"https://openapi.naver.com/v1/search/movie?query=\" + encText + display + yearfrom + yearto # json 결과\n",
        "    # myurl = \"https://openapi.naver.com/v1/search/blog.xml?query=\" + encText # xml 결과\n",
        "    # myurl = 'https://openapi.naver.com/v1/search/movie.json?display=30&query=' + quote('\"' + title + '\"' + '&yearfrom=' + yearfrom + '&yearto=' + yearto) # 확인필요\n",
        "    print(myurl)\n",
        "    request = urllib.request.Request(myurl)\n",
        "    request.add_header(\"X-Naver-Client-Id\",naver_client_id)\n",
        "    request.add_header(\"X-Naver-Client-Secret\",naver_client_secret)\n",
        "    response = urllib.request.urlopen(request)\n",
        "    rescode = response.getcode()\n",
        "    if(rescode==200):\n",
        "        response_body = response.read()\n",
        "        d = json.loads(response_body.decode('utf-8'))\n",
        "        if (len(d['items']) > 0):\n",
        "            return d['items']\n",
        "        else:\n",
        "            return None\n",
        " \n",
        "    else:\n",
        "        print(\"Error Code:\" + rescode)\n",
        " \n",
        "def findItemByInput(items):\n",
        "    df = pd.DataFrame(columns = [ 'navertitle', 'naversubtitle', 'naveruserScore', 'spScore'])\n",
        "    for index, item in enumerate(items):\n",
        "        navertitle = cleanhtml(item['title'])\n",
        "        naversubtitle = cleanhtml(item['subtitle'])\n",
        "        naverpubdate = cleanhtml(item['pubDate'])\n",
        "        naveractor = cleanhtml(item['actor'])\n",
        "        naverlink = cleanhtml(item['link'])\n",
        "        naveruserScore = cleanhtml(item['userRating'])\n",
        " \n",
        "        navertitle1 = navertitle.replace(\" \",\"\")\n",
        "        navertitle1 = navertitle1.replace(\"-\", \",\")\n",
        "        navertitle1 = navertitle1.replace(\":\", \",\")\n",
        " \n",
        "        #기자 평론가 평점을 얻어 옵니다\n",
        "        spScore = getSpecialScore(naverlink)\n",
        " \n",
        "        #네이버가 다루는 영화 고유 ID를 얻어 옵니다\n",
        "        naverid = re.split(\"code=\", naverlink)[1]\n",
        " \n",
        "        # 영화의 타이틀 이미지를 표시합니다\n",
        "        # if (item['image'] != None and \"http\" in item['image']):\n",
        "        #    response = requests.get(item['image'])\n",
        "        #    img = Image.open(BytesIO(response.content))\n",
        "        #    img.show()\n",
        " \n",
        "        # print(index, navertitle, naversubtitle, naveruserScore, spScore)\n",
        "        # print(float(naveruserScore), spScore)\n",
        "        # \n",
        "        if (float(naveruserScore) > 0) & (float(spScore) > 0):\n",
        "            df = df.append({'navertitle' : navertitle\n",
        "                        , 'naversubtitle' : naversubtitle\n",
        "                        , 'naveruserScore' : naveruserScore\n",
        "                        , 'spScore' : spScore} , ignore_index=True)\n",
        "    return df\n",
        "\n",
        " \n",
        "def getInfoFromNaver(searchTitle, yearfrom, yearto):\n",
        "    items = searchByTitle(searchTitle, yearfrom, yearto)\n",
        " \n",
        "    if (items != None):\n",
        "        return findItemByInput(items)\n",
        "    else:\n",
        "        print(\"No result\")\n",
        " \n",
        "def get_soup(url):\n",
        "    source_code = requests.get(url)\n",
        "    plain_text = source_code.text\n",
        "    soup = BeautifulSoup(plain_text, 'lxml')\n",
        "    return soup\n",
        " \n",
        "#기자 평론가 평점을 얻어 옵니다\n",
        "def getSpecialScore(URL):\n",
        "    soup = get_soup(URL)\n",
        "    scorearea = soup.find_all('div', \"spc_score_area\")\n",
        "    newsoup = BeautifulSoup(str(scorearea), 'lxml')\n",
        "    score = newsoup.find_all('em')\n",
        "    if (score and len(score) > 5):\n",
        "        scoreis = score[1].text + score[2].text + score[3].text + score[4].text\n",
        "        return float(scoreis)\n",
        "    else:\n",
        "        return 0.0\n",
        " \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GB_S-cr1kz89"
      },
      "source": [
        "# mv_list = list(set(tmp['movieNm']))\n",
        "# for i in mv_list:\n",
        "#     mv = mv.append(getInfoFromNaver(i))\n",
        "\n",
        "\n",
        "getInfoFromNaver(u'캣츠','2019','2019')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dEunCSouX3_3"
      },
      "source": [
        "mv_list = ['해치지않아',\n",
        " '신비아파트 극장판 하늘도깨비 대 요르문간드',\n",
        " '포드 V 페라리',\n",
        " '시동',\n",
        " '겨울왕국 2',\n",
        " '캣츠',\n",
        " '나이브스 아웃',\n",
        " '백두산',\n",
        " '천문: 하늘에 묻는다',\n",
        " '21 브릿지: 테러 셧다운 ',\n",
        " '미드웨이']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zjhSr-dM1M4n"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ncC-6EXgqZpS"
      },
      "source": [
        "# 영화진흥위원회_일별박스오피스\n",
        "# https://www.kobis.or.kr/kobisopenapi/homepg/apiservice/searchServiceInfo.do\n",
        "\n",
        "import requests\n",
        "import json\n",
        "import pandas as pd\n",
        "import datetime\n",
        "from datetime import timedelta\n",
        "\n",
        "# 0105001\n",
        "url = 'http://www.kobis.or.kr/kobisopenapi/webservice/rest/boxoffice/searchDailyBoxOfficeList.json?key={}&targetDt={}&wideAreaCd=0105001'\n",
        "# 임시 테이블 생성\n",
        "tmp = pd.DataFrame(columns = ['audiAcc','audiChange','audiCnt','audiInten','movieCd','movieNm','openDt','rank','rankInten','rankOldAndNew','rnum','salesAcc','salesAmt','salesChange','salesInten','salesShare','scrnCnt','showCnt','targetDt'])\n",
        "\n",
        "def get_daily_box_office(std_date, i):\n",
        "    target_dt = (std_date + timedelta(days=i)).strftime(\"%Y%m%d\")\n",
        "    print(target_dt)\n",
        "    res = requests.get(url.format(\"bb8624870e8a6533584586cdcc0ffff0\", target_dt))\n",
        "    text = res.text\n",
        "\n",
        "    d = json.loads(text) \n",
        "    movie = []\n",
        "    # print(d)\n",
        "\n",
        "    for b in d['boxOfficeResult']['dailyBoxOfficeList']:\n",
        "        movie.append([  b['audiAcc'],\n",
        "                        b['audiChange'],\n",
        "                        b['audiCnt'],\n",
        "                        b['audiInten'],\n",
        "                        b['movieCd'],\n",
        "                        b['movieNm'],\n",
        "                        b['openDt'],\n",
        "                        b['rank'],\n",
        "                        b['rankInten'],\n",
        "                        b['rankOldAndNew'],\n",
        "                        b['rnum'],\n",
        "                        b['salesAcc'],\n",
        "                        b['salesAmt'],\n",
        "                        b['salesChange'],\n",
        "                        b['salesInten'],\n",
        "                        b['salesShare'],\n",
        "                        b['scrnCnt'],\n",
        "                        b['showCnt']\n",
        "                        ])\n",
        "    df = pd.DataFrame(movie,columns = ['audiAcc','audiChange','audiCnt','audiInten','movieCd','movieNm','openDt','rank','rankInten','rankOldAndNew','rnum','salesAcc','salesAmt','salesChange','salesInten','salesShare','scrnCnt','showCnt'])\n",
        "    df['targetDt'] = target_dt\n",
        "    return df    \n",
        "\n",
        "## std_date = datetime.datetime.strptime('조회 시작일', '%Y-%m-%d')\n",
        "## for i in range(0,조회 하려는 일자 수):\n",
        "#     tmp = tmp.append(get_daily_box_office(std_date, i))\n",
        "##\n",
        "## 예: 조회시작일이 2020-01-01, range(0,2) 인 경우 2020-01-01과 2020-01-02 이틀 조회\n",
        "\n",
        "std_date = datetime.datetime.strptime('2020-01-01', '%Y-%m-%d')\n",
        "for i in range(0,365):\n",
        "    tmp = tmp.append(get_daily_box_office(std_date, i))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YloSHimRz4bo"
      },
      "source": [
        "mv_list = list(set(tmp['movieNm']))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WZIlxV2c0O6y"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CQEXQJrm2eO1"
      },
      "source": [
        "tmp"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VoaQ_uB42ezU"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}